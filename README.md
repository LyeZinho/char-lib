# Character Library (char-lib)

> ğŸ“š Database local de personagens (anime, games*, manga, etc.) usando arquivos JSON
>
> \* *Para jogos, coleta criadores/desenvolvedores; o AutoCrawl ativa automaticamente enrichment via Fandom para buscar personagens reais (nÃ£o apenas criadores)*

Sistema de wiki de personagens 100% em JavaScript, com coleta via APIs pÃºblicas (AniList, RAWG), batch controlado, rate limit e armazenamento incremental em JSON.

## ğŸš€ InÃ­cio RÃ¡pido

```bash
# InstalaÃ§Ã£o
npm install

# Seu primeiro import
node src/cli.js import anime "Naruto" --limit 10

# Ver estatÃ­sticas
node src/cli.js stats anime naruto
```

ğŸ“– **[Guia Completo de InÃ­cio RÃ¡pido â†’](docs/QUICKSTART.md)**

## ğŸ›ï¸ Interface Interativa (TUI)

Interface interativa baseada em menus para **todas as operaÃ§Ãµes** disponÃ­veis:

```bash
# Iniciar interface interativa
npm run tui
# ou
node src/cli.js interactive
```

### ğŸ“‹ Funcionalidades Completas

#### ğŸ“¥ **Importar Obra**
- Importar anime, manga ou jogos
- Configurar limite de personagens
- Ajustar delay entre requisiÃ§Ãµes

#### ğŸ” **Buscar Personagens**
- Busca local em obras especÃ­ficas
- Filtragem por tipo (anime/manga/game)

#### ğŸ“Š **Ver EstatÃ­sticas**
- EstatÃ­sticas detalhadas de obras
- Contagem por roles de personagens

#### ğŸ”„ **Atualizar Dados**
- Atualizar todas as obras existentes
- OpÃ§Ã£o de pular personagens
- Suporte a enrichment como fallback

#### ğŸ¤– **Auto-Crawling** (Menu Completo)
- ğŸš€ **Executar Crawling**: Processar obras da fila
- ğŸ“Š **Ver Status**: Estado atual do crawler
- ğŸ“‹ **Listar Processadas**: Ãndice de obras processadas
- ğŸ§¹ **Limpar Fila**: Resetar fila pendente
- â• **Aumentar Fila**: Descobrir mais obras populares
- ğŸ”„ **AutoCraw ContÃ­nuo**: Crawling automÃ¡tico contÃ­nuo
- ğŸ¯ **Smart Queue**: Sistema inteligente de alternÃ¢ncia entre tipos
- ğŸ§ **Smart Queue Daemon**: Gerenciamento do daemon Linux

#### ğŸ“‹ **Listar Obras**
- Listar todas as obras por tipo
- Filtrar por anime, manga ou games

#### âœ… **Validar Dados**
- ValidaÃ§Ã£o completa contra schemas JSON
- RelatÃ³rio de erros detalhado

#### ğŸ’¾ **Gerenciar Cache**
- ğŸ“Š **Ver Status**: EstatÃ­sticas do cache
- ğŸ§¹ **Limpar Cache**: Reset completo
- ğŸ”„ **Reconstruir Cache**: Reconstruir baseado em dados existentes

#### ğŸš€ **Deploy Web**
- Atualizar dados do frontend
- Copiar database para interface web

#### ğŸ› ï¸ **Scripts Ãšteis**
- ğŸ“Š **Gerar Ãndices**: Criar arquivos index.json para API web
- ğŸ® **Importar Jogos**: Executar script de importaÃ§Ã£o de jogos
- ğŸ¤– **Exemplo de Crawling**: DemonstraÃ§Ã£o de funcionalidades de crawling

### ğŸ¯ NavegaÃ§Ã£o

- **Setas â†‘â†“**: Navegar entre opÃ§Ãµes
- **Enter**: Selecionar opÃ§Ã£o
- **Menus aninhados**: Submenus para funcionalidades complexas
- **ConfirmaÃ§Ãµes**: ValidaÃ§Ãµes para operaÃ§Ãµes destrutivas

### ğŸ’¡ Dicas

- Use o modo interativo para descobrir todas as opÃ§Ãµes disponÃ­veis
- As configuraÃ§Ãµes padrÃ£o sÃ£o otimizadas para uso geral
- OperaÃ§Ãµes de crawling suportam apenas anime e manga (games nÃ£o tÃªm personagens fictÃ­cios)
- O cache acelera verificaÃ§Ãµes de obras jÃ¡ processadas

## âš¡ Controle de Rate Limit

Novo parÃ¢metro `--delay` para controlar o tempo entre requisiÃ§Ãµes e evitar bans:

```bash
# Import com delay de 3 segundos entre pÃ¡ginas
node src/cli.js import anime "One Piece" --limit 100 --delay 3000

# Crawling com delay maior para execuÃ§Ãµes longas
node src/cli.js crawl --max-works 50 --delay 5000
```

**Por que isso importa:**
- Evita erros "too many requests"
- Permite execuÃ§Ãµes longas sem interrupÃ§Ã£o
- Respeita as APIs de terceiros

## ğŸ¤– Auto-Crawling (Novo!)

Sistema automÃ¡tico que descobre e importa obras populares do AniList:

```bash
# Executar crawling automÃ¡tico (10 obras por vez)
npm run crawl

# Ver status do crawling
npm run crawl-status

# Listar obras jÃ¡ processadas
npm run crawl-list

# Aumentar a fila com mais obras
npm run crawl-grow -- --count 50

# Crawling personalizado
node src/cli.js crawl --max-works 5 --character-limit 25 --delay 10000

# Para mangas (igual ao anime)
node src/cli.js crawl --type manga --max-works 3
```

**Nota:** Jogos nÃ£o sÃ£o suportados por enquanto (RAWG nÃ£o oferece personagens fictÃ­cios, apenas criadores/desenvolvedores).

**Como funciona:**
- ğŸ” Descobre automaticamente animes populares
- ğŸ“‹ MantÃ©m fila de obras pendentes
- âœ… Rastreia progresso em `data/crawl-state.json`
- â±ï¸ Respeita rate limits das APIs

## ğŸš€ AutoCraw ContÃ­nuo (Novo!)

Sistema autÃ´nomo de crawling contÃ­nuo com enrichment inteligente:

```bash
# Executar crawling contÃ­nuo (recomendado)
npm run autocraw

# Com configuraÃ§Ãµes personalizadas
node src/cli.js autocraw --max-works 3 --delay 20000 --max-total 50

# Apenas para teste (limite pequeno)
node src/cli.js autocraw --max-works 1 --max-total 2 --delay 5000
```

**CaracterÃ­sticas:**
- ğŸ¤– **Totalmente autÃ´nomo**: Roda indefinidamente atÃ© ser interrompido (Ctrl+C)
- ğŸ”„ **Ciclos inteligentes**: Processa lotes e continua automaticamente
- ğŸ›¡ï¸ **Enrichment fallback**: Usa DuckDuckGo/wikis quando APIs atingem rate limit
- ğŸ“Š **Limite opcional**: Configure `--max-total` para limitar obras processadas
- â±ï¸ **Rate limit seguro**: Delays configurÃ¡veis para evitar bloqueios

**Como funciona:**
1. Processa obras da fila em ciclos
2. Quando APIs falham (429), usa enrichment como fallback
3. Continua atÃ© fila vazia ou limite atingido
4. Pode ser interrompido a qualquer momento
- ğŸ“Š Gera Ã­ndice para pesquisa futura

## ğŸ¯ Smart Queue (Daemon Linux)

Sistema inteligente de fila que roda como **processo Linux** (daemon), alterna entre tipos de conteÃºdo para otimizaÃ§Ã£o mÃ¡xima de coleta:

### ğŸš€ InstalaÃ§Ã£o como ServiÃ§o

```bash
# Instalar como serviÃ§o systemd (requer sudo)
npm run smart-queue-install

# Ou diretamente
sudo bash scripts/install-smart-queue-service.sh
```

### ğŸ› ï¸ Gerenciamento do Daemon

```bash
# Iniciar daemon (modo serviÃ§o systemd)
npm run smart-queue-start

# Parar daemon
npm run smart-queue-stop

# Reiniciar daemon
npm run smart-queue-restart

# Ver status detalhado
npm run smart-queue-service-status

# Ver logs (Ãºltimas 50 linhas)
npm run smart-queue-logs

# Seguir logs em tempo real
npm run smart-queue-logs -- --follow

# Resetar estado e logs
npm run smart-queue-service-reset
```

### â–¶ï¸ Executar Smart Queue (Local vs ServiÃ§o)

```bash
# Modo local (desenvolvimento / testes): executa no terminal atual
npm run smart-queue

# Iniciar como serviÃ§o systemd (produÃ§Ã£o) â€” inicia o service com sudo
node src/cli.js smart-queue --service
# ou use o helper que usa systemctl:
npm run smart-queue-start

# ObservaÃ§Ã£o: Ao executar `npm run smart-queue` o CLI tentarÃ¡ detectar se o serviÃ§o
# systemd `smart-queue` estÃ¡ instalado/enabled e, se estiver, solicitarÃ¡ seu start
# automaticamente (pode solicitar senha sudo). Para forÃ§ar execuÃ§Ã£o local, use:
# node src/cli.js smart-queue --force-local

# PermissÃµes e diretÃ³rio de dados
# O instalador tenta ajustar permissÃµes do diretÃ³rio configurado em `/etc/smart-queue/config.json` (campo `baseDir`).
# Se vocÃª quiser usar o diretÃ³rio do repositÃ³rio, garanta que o usuÃ¡rio do serviÃ§o (`smartqueue`) tenha permissÃ£o de escrita:
# sudo chown -R smartqueue:smartqueue /home/pedro/projetos/char-lib/data
# Ou altere `baseDir` para um diretÃ³rio em /var/lib e deixe o instalador cuidar das permissÃµes.

# Comportamento de Ciclos
# Por padrÃ£o o daemon executa 1 ciclo por chamada (processa um tipo por vez) com delays conservativos entre tipos e ciclos.
# - Para executar continuamente sem parar entre ciclos, configure `cyclesPerRun` como 0.
# - Exemplo: no serviÃ§o (via CLI):
#   node src/cli.js smart-queue --service --cycles-per-run 0 --auto-deploy --deploy-threshold 5 --enrich
# - Ou edite /etc/smart-queue/config.json e ajuste `"cyclesPerRun": 0` e reinicie o serviÃ§o.

# Uso recomendado:
# - Em produÃ§Ã£o: instale o serviÃ§o e inicie com systemd
# - Em desenvolvimento: execute localmente com npm run smart-queue
```

### âš™ï¸ ConfiguraÃ§Ã£o

**CaracterÃ­sticas:**
- ğŸ§ **Daemon Linux**: Roda como processo do sistema (systemd)
- ğŸ›¡ï¸ **Ultra-conservativo**: Rate limiting de 5 req/min (12s mÃ­nimo) para AniList
- ğŸ”„ **Background persistente**: Continua rodando mesmo apÃ³s logout
- ğŸ“Š **Estado persistente**: Salva progresso automaticamente
- ğŸ¯ **Balanceado**: Processa quantidades iguais de cada tipo
- â±ï¸ **Long-running**: Projetado para execuÃ§Ã£o indefinida
- ğŸš€ **Auto-Deploy**: Deploy automÃ¡tico da database a cada X obras

**Como funciona:**
1. Instalado como serviÃ§o systemd com usuÃ¡rio dedicado
2. Alterna entre tipos (anime â†’ manga â†’ anime...) automaticamente
3. Processa lote de cada tipo antes de alternar
4. **Executa auto-deploy automaticamente** quando atinge threshold
5. Logs salvos em `/var/log/smart-queue.log`
6. Estado salvo em `data/smart-queue-state.json`
7. Pode ser monitorado e controlado via systemctl

### ğŸ“Š Monitoramento

```bash
# Status completo do serviÃ§o
npm run smart-queue-service-status

# Ver logs recentes
npm run smart-queue-logs

# Seguir logs ao vivo
npm run smart-queue-logs -- --follow

# Verificar com systemctl
sudo systemctl status smart-queue
```

### ğŸ›‘ Controle AvanÃ§ado

```bash
# Comandos systemctl diretos
sudo systemctl start smart-queue
sudo systemctl stop smart-queue
sudo systemctl restart smart-queue
sudo systemctl enable smart-queue    # Auto-inÃ­cio
sudo systemctl disable smart-queue   # Desabilitar auto-inÃ­cio

# Ver logs do sistema
journalctl -u smart-queue -f
journalctl -u smart-queue --since today
```

### ï¿½ Auto-Deploy AutomÃ¡tico

**Deploy automÃ¡tico da database** a cada X obras processadas:

```bash
# Executar com auto-deploy (deploy a cada 10 obras)
npm run smart-queue-with-deploy

# Com threshold customizado
node src/cli.js smart-queue --auto-deploy --deploy-threshold 5

# No daemon (habilitar no config)
# Editar /etc/smart-queue/config.json:
{
  "autoDeployEnabled": true,
  "autoDeployThreshold": 10
}
```

**O que o auto-deploy faz:**
1. âœ… `npm run generate-indexes` - Gera Ã­ndices de pesquisa
2. âœ… `npm run validate` - Valida integridade da database
3. âœ… `npm run deploy` - Faz deploy para interface web
4. âœ… `git add .` - Adiciona mudanÃ§as ao staging
5. âœ… `git commit -m "automatic db update DD/MM/YYYY-HH:MM:SS: queue X works YMB"`

**Vantagens:**
- ğŸ”„ **AutomaÃ§Ã£o completa**: Deploy automÃ¡tico apÃ³s processamento
- ğŸ“Š **HistÃ³rico versionado**: Commits automÃ¡ticos com timestamp
- âœ… **ValidaÃ§Ã£o**: Database validada antes do deploy
- ğŸŒ **Web atualizada**: Interface web sempre atualizada
- ğŸ“ **Logs detalhados**: Acompanhamento completo das operaÃ§Ãµes

**Para deploy final:**
```bash
# ApÃ³s auto-deploy, fazer push manual
git push origin main
```

## âœ¨ Features

- ğŸ¯ **Database JSON local** - Sem dependÃªncia de banco de dados externo
- ğŸ”„ **Import incremental** - Merge inteligente sem duplicaÃ§Ã£o
- ğŸ¤– **Auto-Crawling** - Descoberta automÃ¡tica de obras populares
- ğŸ¯ **Smart Queue** - Sistema inteligente de alternÃ¢ncia entre tipos de conteÃºdo
- ğŸ§ **Daemon Linux** - Smart Queue como serviÃ§o systemd persistente
- ï¿½ **API AniList** - Coleta de animes e mangas
- ğŸ® **API RAWG** - Coleta de jogos e criadores
- ğŸ” **Enrichment System** - Fallback para wikis quando APIs atingem limite
- âš¡ **Rate limiting** - Respeita limites das APIs
- ğŸ” **Busca local** - Query rÃ¡pida nos dados importados
- âœ… **ValidaÃ§Ã£o JSON Schema** - Garante consistÃªncia dos dados
- ğŸ¨ **CLI completa** - Interface de linha de comando amigÃ¡vel
- ğŸ”§ **ExtensÃ­vel** - Arquitetura preparada para novas fontes de dados

## ğŸ” Sistema de Enrichment

Para evitar dependÃªncia excessiva de APIs e erros de rate limit, o sistema inclui um **Enrichment Collector** que:

- ğŸ” **Busca no DuckDuckGo** por wikis e fontes complementares
- ğŸ“– **Integra dados de Fandom** e outras wikis pÃºblicas
- ğŸ›¡ï¸ **Fallback automÃ¡tico** quando APIs principais atingem limite
- ğŸ”— **Adiciona links externos** para mais informaÃ§Ãµes

```bash
# AtualizaÃ§Ã£o com enrichment ativado
node src/cli.js update --enrich

# AtualizaÃ§Ã£o apenas de informaÃ§Ãµes (sem personagens)
node src/cli.js update --no-characters --enrich
```

**Como funciona:**
- Quando uma API retorna erro 429 (rate limit), o sistema automaticamente busca informaÃ§Ãµes complementares
- Adiciona links para wikis do Fandom, Anime-Planet e outras fontes
- MantÃ©m dados principais das APIs quando disponÃ­veis
- Reduz dependÃªncia de uma Ãºnica fonte de dados

## ğŸ“ Estrutura do Projeto

\`\`\`
char-lib/
â”œâ”€â”€ data/                    # Database JSON
â”‚   â”œâ”€â”€ anime/
â”‚   â”‚   â””â”€â”€ naruto/
â”‚   â”‚       â”œâ”€â”€ info.json
â”‚   â”‚       â””â”€â”€ characters.json
â”‚   â”œâ”€â”€ manga/
â”‚   â””â”€â”€ game/
â”‚
â”œâ”€â”€ schemas/                 # JSON Schemas
â”‚   â”œâ”€â”€ work.schema.json
â”‚   â”œâ”€â”€ character.schema.json
â”‚   â””â”€â”€ characters_collection.schema.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ collectors/         # APIs / coleta de dados
â”‚   â”‚   â””â”€â”€ anilist.js
â”‚   â”œâ”€â”€ normalizers/        # TransformaÃ§Ã£o de dados
â”‚   â”‚   â””â”€â”€ anilist.js
â”‚   â”œâ”€â”€ writers/            # Escrita incremental
â”‚   â”‚   â””â”€â”€ jsonWriter.js
â”‚   â”œâ”€â”€ jobs/               # OrquestraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ importWork.js
â”‚   â”œâ”€â”€ utils/              # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ file.js
â”‚   â”‚   â”œâ”€â”€ slugify.js
â”‚   â”‚   â”œâ”€â”€ rateLimiter.js
â”‚   â”‚   â”œâ”€â”€ retry.js
â”‚   â”‚   â”œâ”€â”€ logger.js
â”‚   â”‚   â””â”€â”€ validator.js
â”‚   â””â”€â”€ cli.js              # Interface CLI
â”‚
â””â”€â”€ package.json
\`\`\`

## ğŸš€ InstalaÃ§Ã£o

\`\`\`bash
# Clone o repositÃ³rio
git clone https://github.com/LyeZinho/char-lib.git
cd char-lib

# Instale as dependÃªncias
npm install

# (Opcional) Link global para usar como comando
npm link
\`\`\`

## ğŸ“– Uso

### Importar uma obra

\`\`\`bash
# Importar anime por nome
node src/cli.js import anime "Naruto"

# Importar por ID do AniList
node src/cli.js import anime naruto --id 20

# Importar apenas info (sem personagens)
node src/cli.js import anime "One Piece" --skip-characters

# Limitar nÃºmero de personagens
node src/cli.js import anime "Bleach" --limit 50
\`\`\`

### Validar dados

\`\`\`bash
# Validar obra especÃ­fica
node src/cli.js validate anime naruto

# Listar schemas disponÃ­veis
node src/cli.js validate
\`\`\`

### Buscar personagens

\`\`\`bash
# Buscar em obra especÃ­fica
node src/cli.js search "Uzumaki" --type anime --work naruto

# Filtrar por role
node src/cli.js search "Sasuke" --type anime --work naruto --role protagonist
\`\`\`

### EstatÃ­sticas

\`\`\`bash
# Ver stats de uma obra
node src/cli.js stats anime naruto
\`\`\`

### Listar obras

\`\`\`bash
# Listar todas as obras
node src/cli.js list

# Listar apenas animes
node src/cli.js list anime
\`\`\`

### Deploy para Web

Atualiza a base de dados pÃºblica do site, sincronizando o diretÃ³rio \`web/public/data\` com os dados atuais do projeto:

\`\`\`bash
# Executar deploy
npm run deploy

# Ou diretamente
node src/cli.js deploy
\`\`\`

**O que faz:**
- ğŸ—‘ï¸ **Remove** o diretÃ³rio antigo \`web/public/data\`
- ğŸ“‹ **Copia** todo o conteÃºdo de \`data/\` para \`web/public/data\`
- âœ… **Atualiza** a base de dados pÃºblica do site com dados frescos

## ğŸ“Š Estrutura dos Dados

### info.json (InformaÃ§Ãµes da Obra)

\`\`\`json
{
  "id": "naruto",
  "type": "anime",
  "title": "Naruto",
  "alt_titles": ["ãƒŠãƒ«ãƒˆ"],
  "source": "AniList",
  "source_id": 20,
  "description": "Anime sobre ninjas...",
  "metadata": {
    "format": "TV",
    "episodes": 220,
    "status": "FINISHED",
    "startDate": "2002-10-03",
    "genres": ["Action", "Adventure"]
  },
  "images": [
    {
      "url": "https://...",
      "type": "cover",
      "source": "AniList"
    }
  ],
  "external_ids": {
    "anilist": 20
  },
  "tags": ["ninja", "shounen"],
  "updated_at": "2025-12-22T10:00:00.000Z"
}
\`\`\`

### characters.json (Personagens)

\`\`\`json
{
  "work_id": "naruto",
  "count": 1,
  "updated_at": "2025-12-22T10:05:00.000Z",
  "characters": [
    {
      "id": "uzumaki_naruto",
      "name": "Naruto Uzumaki",
      "alt_names": ["ã†ãšã¾ããƒŠãƒ«ãƒˆ"],
      "role": "protagonist",
      "description": "Ninja da Vila da Folha...",
      "metadata": {
        "gender": "male",
        "age": "12-17"
      },
      "images": [
        {
          "url": "https://...",
          "type": "portrait",
          "source": "AniList"
        }
      ],
      "external_ids": {
        "anilist": 17
      }
    }
  ]
}
\`\`\`

## ğŸ§± Arquitetura

### Fluxo de ImportaÃ§Ã£o

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI       â”‚  node src/cli.js import anime "Naruto"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ImportJob   â”‚  Orquestra o processo
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚ Collector  â”‚  Busca dados na API AniList
       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (com rate limit e retry)
       â”‚
       â”œâ”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚ Normalizer â”‚  Transforma para nosso schema
       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Writer   â”‚  Salva/merge nos arquivos JSON
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Componentes Principais

- **Collectors**: Fazem requisiÃ§Ãµes Ã s APIs externas (AniList, MAL, etc)
- **Normalizers**: Transformam dados externos para nosso formato padrÃ£o
- **Writers**: Gerenciam escrita incremental e deduplicaÃ§Ã£o
- **Jobs**: Orquestram o fluxo completo de importaÃ§Ã£o
- **Utils**: Rate limiting, retry, validaÃ§Ã£o, file I/O

## ğŸ”§ Desenvolvimento

### Adicionar nova fonte de dados

1. Criar collector em `src/collectors/`
2. Criar normalizer em `src/normalizers/`
3. Adicionar opÃ§Ã£o na CLI

Exemplo:

\`\`\`javascript
// src/collectors/myanimelist.js
export class MALCollector {
  async searchAnime(query) {
    // Implementar coleta
  }
}

// src/normalizers/myanimelist.js
export function normalizeMALData(data) {
  // Transformar para nosso schema
  return {
    id: slugify(data.title),
    type: 'anime',
    title: data.title,
    // ...
  };
}
\`\`\`

### Rate Limits

- **AniList**: ~90 requisiÃ§Ãµes/minuto (configurado em `anilist.js`)
- AjustÃ¡vel via `RateLimiter` class

### ValidaÃ§Ã£o

Todos os dados sÃ£o validados contra JSON Schemas antes de serem salvos.

\`\`\`bash
# Validar manualmente
node src/cli.js validate anime naruto
\`\`\`

## âš ï¸ LimitaÃ§Ãµes das APIs

### DescriÃ§Ãµes de Personagens

**MyAnimeList (MAL)**: A API Jikan nÃ£o fornece descriÃ§Ãµes detalhadas dos personagens. Quando importado via `--source mal`, os personagens terÃ£o uma mensagem explicativa no campo `description`:

```json
{
  "description": "DescriÃ§Ã£o nÃ£o disponÃ­vel via MyAnimeList. Use --source anilist para obter descriÃ§Ãµes completas dos personagens."
}
```

**AniList**: Fornece descriÃ§Ãµes completas e ricas dos personagens. Recomendado para importaÃ§Ãµes que precisam de informaÃ§Ãµes detalhadas.

### RecomendaÃ§Ã£o

Para obter descriÃ§Ãµes completas dos personagens, sempre use:

```bash
node src/cli.js import anime "Nome do Anime" --source anilist
```

### Rate Limits

- **AniList**: ~90 requisiÃ§Ãµes/minuto (configurado em `anilist.js`)
- **MyAnimeList (Jikan)**: ~60 requisiÃ§Ãµes/minuto
- AjustÃ¡vel via classes `RateLimiter`

## ğŸ—ºï¸ Roadmap

### Fase 1 - Base âœ…
- [x] Estrutura do projeto
- [x] JSON Schemas
- [x] Writer incremental
- [x] CLI bÃ¡sica

### Fase 2 - Coleta âœ…
- [x] AniList collector
- [x] Batch + rate limit
- [x] PaginaÃ§Ã£o automÃ¡tica

### Fase 3 - ExpansÃ£o ğŸš§
- [ ] MyAnimeList collector
- [ ] IGDB collector (games)
- [ ] DeduplicaÃ§Ã£o avanÃ§ada (similaridade de strings)
- [ ] Cache de requisiÃ§Ãµes
- [ ] Testes unitÃ¡rios

### Fase 4 - Qualidade ğŸ“‹
- [ ] Logs estruturados
- [ ] MÃ©tricas de importaÃ§Ã£o
- [ ] ExportaÃ§Ã£o para outros formatos
- [ ] API REST local (opcional)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

ğŸ“– **[Guia de Desenvolvimento â†’](docs/DEVELOPMENT.md)**

## ğŸ“š DocumentaÃ§Ã£o

- **[ğŸš€ InÃ­cio RÃ¡pido](docs/QUICKSTART.md)** - Comece em 5 minutos
- **[ğŸ“‹ Exemplos](docs/EXAMPLES.md)** - Casos de uso prÃ¡ticos
- **[ğŸ—ï¸ Estrutura](docs/STRUCTURE.md)** - Arquitetura do projeto
- **[ğŸ’» Desenvolvimento](docs/DEVELOPMENT.md)** - Guia para contribuidores

## ğŸ“ LicenÃ§a

MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ”— Links Ãšteis

- [AniList API Documentation](https://anilist.gitbook.io/anilist-apiv2-docs/)
- [JSON Schema](https://json-schema.org/)
- [Commander.js](https://github.com/tj/commander.js)

---

**Feito com â¤ï¸ por LyeZinho**
