# ü§ñ Sistema de Auto-Crawling

O sistema de auto-crawling permite descobrir e importar automaticamente obras populares do AniList, mantendo um √≠ndice de progresso e respeitando limites de API.

## Como Funciona

1. **Descoberta**: Busca as obras mais populares no AniList
2. **Fila**: Mant√©m uma lista de obras pendentes para processamento
3. **Processamento**: Importa obras uma por vez com delay controlado
4. **Estado**: Salva progresso em `data/crawl-state.json`
5. **√çndice**: Mant√©m registro de todas as obras processadas

## Comandos

### Executar Crawling

```bash
# Crawling b√°sico (10 obras por execu√ß√£o)
npm run crawl

# Personalizar quantidade e limites
node src/cli.js crawl --max-works 5 --character-limit 25 --delay 10000

# Continuar da fila existente
node src/cli.js crawl --continue --max-works 3
```

### Gerenciar Estado

```bash
# Ver status atual
npm run crawl-status

# Listar obras processadas
npm run crawl-list

# Aumentar a fila com mais obras
npm run crawl-grow -- --count 50

# Limpar fila pendente
node src/cli.js crawl-clear
```

### Aumentar Fila

O comando `crawl-grow` permite expandir a fila de obras sem executar o processamento:

```bash
# Adicionar 20 obras populares (padr√£o)
npm run crawl-grow

# Adicionar 50 obras espec√≠ficas
node src/cli.js crawl-grow --count 50 --page 2
```

**Como funciona:**
- üîç Busca animes populares no AniList (ordenados por popularidade)
- üö´ Filtra obras j√° processadas ou j√° na fila
- ‚ûï Adiciona apenas obras novas √† fila
- üìÑ Suporta m√∫ltiplas p√°ginas para obter mais obras

### Exemplos

```bash
# Exemplo completo
npm run crawl-example
```

## Arquivo de Estado

O arquivo `data/crawl-state.json` mant√©m:

```json
{
  "processedWorks": ["16498", "101922", "1535"],
  "queue": [
    {
      "id": 113415,
      "title": "Jujutsu Kaisen",
      "popularity": 838625,
      "score": 84,
      "episodes": 24,
      "status": "FINISHED"
    }
  ],
  "stats": {
    "totalProcessed": 3,
    "totalCharacters": 150,
    "lastRun": "2025-12-22T12:23:50.627Z"
  }
}
```

## Op√ß√µes de Configura√ß√£o

| Op√ß√£o | Padr√£o | Descri√ß√£o |
|-------|--------|-----------|
| `--max-works` | 10 | M√°ximo de obras por execu√ß√£o |
| `--character-limit` | 50 | Limite de personagens por obra |
| `--delay` | 2000 | Delay entre importa√ß√µes (ms) |
| `--continue` | false | Continuar da fila existente |
| `--base-dir` | ./data | Diret√≥rio dos dados |
| `--enrich` | false | Quando usado com jogos (`--type game`), tenta buscar personagens via DuckDuckGo/wikis (experimental) |

## Rate Limiting

- **Descoberta**: ~60 req/min (limite do AniList)
- **Importa√ß√£o**: ~60 req/min por obra
- **Delay**: 10 segundos entre importa√ß√µes por padr√£o
- **P√°ginas**: 1 segundo entre p√°ginas de personagens

## Estrat√©gia de Descoberta

1. Busca top 20 animes mais populares
2. Filtra obras j√° processadas
3. Adiciona novas obras √† fila
4. Processa em ordem de popularidade

## Casos de Uso

### Construir Database Inicial

```bash
# Importar top 50 obras populares
for i in {1..5}; do
  node src/cli.js crawl --max-works 10 --character-limit 100
  sleep 60  # Esperar rate limit reset
done
```

### Manuten√ß√£o Cont√≠nua

```bash
# Script di√°rio para novas obras
#!/bin/bash
node src/cli.js crawl --max-works 5 --continue
```

### Backup e Restaura√ß√£o

```bash
# Fazer backup do estado
cp data/crawl-state.json backup/

# Restaurar estado
cp backup/crawl-state.json data/
```

## Monitoramento

### Ver Progresso

```bash
# Status detalhado
npm run crawl-status

# Estat√≠sticas gerais
node src/cli.js stats anime $(node src/cli.js crawl-list | grep -o '[0-9]\+' | head -1)
```

### Logs

Os logs mostram:
- üìä Configura√ß√£o atual
- üîç N√∫mero de obras descobertas
- üöÄ Progresso de cada importa√ß√£o
- ‚è≥ Delays entre importa√ß√µes
- ‚úÖ Relat√≥rio final

## Troubleshooting

### Fila Vazia

Se a fila estiver vazia, execute sem `--continue`:

```bash
node src/cli.js crawl  # Descobrir√° novas obras
```

### Rate Limit Excedido

Aumente o delay entre importa√ß√µes:

```bash
node src/cli.js crawl --delay 5000 --max-works 3
```

### Estado Corrompido

Recrie o estado:

```bash
rm data/crawl-state.json
node src/cli.js crawl  # Come√ßar√° do zero
```

## Extens√µes Futuras

- **Filtros**: Por g√™nero, ano, status
- **Prioriza√ß√£o**: Baseada em score/popularidade
- **Agendamento**: Execu√ß√£o autom√°tica peri√≥dica
- **M√∫ltiplas fontes**: Suporte a MAL, IGDB
- **Paraleliza√ß√£o**: M√∫ltiplos workers
- **Webhooks**: Notifica√ß√µes de progresso